import os

# API 密钥  (请替换成你的实际密钥)
CEREBRAS_API_KEY = os.environ.get("CEREBRAS_API_KEY")
GROQ_API_KEY = os.environ.get("GROQ_API_KEY")
GEMINI_API_KEY = os.environ.get("GEMINI_API_KEY")
SAMBANOVA_API_KEY = os.environ.get("SAMBANOVA_API_KEY")
# LMstudio API configuration
LMSTUDIO_BASE_URL = "http://localhost:1234/v1"
LMSTUDIO_API_KEY = "not-needed"  # LMstudio doesn't require API key
# Kobold API configuration 
KOBOLD_BASE_URL = "http://localhost:5001/v1"
KOBOLD_API_KEY = "not-needed"  # Kobold doesn't require API key
# Ollama API configuration
OLLAMA_BASE_URL = "http://localhost:11434/v1"
OLLAMA_API_KEY = "ollama"  # required but unused

# 可用模型列表
AVAILABLE_MODELS = [
    "[Cerebras] llama3.1-70b",
    "[Cerebras] llama3.1-8b",
    "[Groq] mixtral-8x7b-32768",
    "[Groq] llama-3.1-70b-versatile",
    "[Groq] llama-3.1-8b-instant",
    "[Groq] llama-3.2-90b-vision-preview",
    "[Groq] llama-3.3-70b-versatile",
    "[Groq] llama-3.3-70b-specdec",
    "[Gemini] gemini-1.5-flash-002",
    "[Gemini] gemini-1.5-flash-8b",
    "[Gemini] gemini-exp-1206",
    "[SambaNova] Meta-Llama-3.1-8B-Instruct",
    "[SambaNova] Meta-Llama-3.1-70B-Instruct",
    "[SambaNova] Meta-Llama-3.1-405B-Instruct",
    "[SambaNova] Qwen2.5-72B-Instruct",
    "[SambaNova] Qwen2.5-Coder-32B-Instruct"
]

def get_api_models(base_url, prefix):
    try:
        import requests
        response = requests.get(f"{base_url}/models", timeout=1)
        models_data = response.json()
        return [f"[{prefix}] {model['id']}" for model in models_data['data']]
    except:
        return []

def get_lmstudio_models():
    return get_api_models(LMSTUDIO_BASE_URL, "LMstudio")
    
def get_kobold_models():
    return get_api_models(KOBOLD_BASE_URL, "Kobold")

def get_ollama_models():
    return get_api_models(OLLAMA_BASE_URL, "Ollama")

# Function to refresh available models
def refresh_available_models(include_local=False):
    """刷新可用模型列表
    Args:
        include_local (bool): 是否包含本地模型
    """
    global AVAILABLE_MODELS
    # 保留云端模型
    base_models = [m for m in AVAILABLE_MODELS if not m.startswith(("[LMstudio]", "[Kobold]", "[Ollama]"))]
    
    if include_local:
        # 获取本地模型
        lmstudio_models = get_lmstudio_models()
        kobold_models = get_kobold_models()
        ollama_models = get_ollama_models()
        AVAILABLE_MODELS = base_models + lmstudio_models + kobold_models + ollama_models
    else:
        AVAILABLE_MODELS = base_models

# 默认文件夹路径 (使用占位符)
DEFAULT_FOLDER_PATH = os.path.dirname(__file__)

# 默认模型
DEFAULT_MODEL = AVAILABLE_MODELS[0]

# 默认温度
DEFAULT_TEMPERATURE = "1.0"

# Default theme
DEFAULT_THEME = "light"

# Theme colors
THEMES = {
    "light": {
        "window_bg": "#F5F5F5",   # 主窗口略微灰色
        "text": "#000000",
        "input_bg": "#FFFFFF",
        "input_border": "#CCCCCC",
        "button_bg": "#0078D7",
        "button_hover": "#005A9E",
        "button_text": "#FFFFFF",
        "title_button_hover": "#E81123",
        "sidebar_bg": "#EBEBEB"  # 更改为浅灰色，比window_bg更浅
    },
    "dark": {
        "window_bg": "#2D2D2D",   # 保持原来的深色
        "text": "#FFFFFF",
        "input_bg": "#3D3D3D",
        "input_border": "#555555",
        "button_bg": "#0078D7",
        "button_hover": "#005A9E",
        "button_text": "#FFFFFF",
        "title_button_hover": "#E81123",
        "sidebar_bg": "#252525"  # 更改为比window_bg稍深的颜色
    }
}